{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe405f77-5b97-4f48-aa28-72ad7d9282ac",
   "metadata": {},
   "source": [
    "# Algoritmo Perceptron (Fase Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1d53887f-8581-47bb-9b99-9bbe7f2a2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3077eb74-6e47-41b0-8768-1b8ce5d8ad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "# valores de entrada\n",
    "X = np.array([\n",
    "    [-1, 0.1, 0.4, 0.7],\n",
    "    [-1, 0.3, 0.7, 0.2],\n",
    "    [-1, 0.6, 0.9, 0.8],\n",
    "    [-1, 0.5, 0.7, 0.1],\n",
    "])\n",
    "\n",
    "d = np.array([1, -1, -1, 1]) # valores de X\n",
    "\n",
    "w = np.array([0.03, 0.04, 0.022, 0.005]) # pesos\n",
    "#w = np.array([-0.05 ,  0.146, -0.174,  0.011])\n",
    "\n",
    "n = 0.01 # taxa de aprendizagem\n",
    "\n",
    "def sinal(x):\n",
    "    return np.where(x >= 0, 1, -1)\n",
    "\n",
    "contador_epocas = 0\n",
    "\n",
    "while contador_epocas <= 200:\n",
    "    \n",
    "    erro = False\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        u = np.dot(w, X[i])\n",
    "        y = sinal(u)\n",
    "        \n",
    "        if y != d[i]:\n",
    "            w = w + n * (d[i] - y) * X[i]\n",
    "            erro = True\n",
    "            \n",
    "    contador_epocas += 1\n",
    "    \n",
    "    if not erro:\n",
    "        break\n",
    "print(contador_epocas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c18f3f-b11c-4e5b-a83e-047485584445",
   "metadata": {},
   "source": [
    "# Fase de Operação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7df88757-b12b-4683-aed1-e8d848a6e269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertence a classe B\n"
     ]
    }
   ],
   "source": [
    "amostra_x = np.array([-1, 0.5, 0.7, 0.1],)\n",
    "\n",
    "peso_treinamento = w.copy()\n",
    "\n",
    "u_operacao = np.dot(peso_treinamento, amostra_x)\n",
    "\n",
    "y_operacao = sinal(u_operacao)\n",
    "\n",
    "if y_operacao == -1:\n",
    "    print(\"Pertence a classe A\")\n",
    "if y_operacao == 1:\n",
    "    print(\"Pertence a classe B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7ab17-9304-4b38-98b4-22cc20e65991",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387c371-df45-4f8f-9d70-9a4d69fe0399",
   "metadata": {},
   "source": [
    "1) *Explique como se processa a regra de Hebb no contexto do algortimo de aprenziado do Perceptron*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2995b46-bb8d-4f98-89f4-32087ce3e038",
   "metadata": {},
   "source": [
    "*R*: Caso a saída produzida pelo Perceptron não coincida com a saída desejada, os pesos sinápticos e o limiar (ou viés) são ajustados proporcionalmente aos valores de entrada, segundo a regra de atualização do Perceptron. Por outro lado, se a saída estiver correta, nenhuma atualização é realizada. Esse processo é repetido iterativamente para todas as amostras do conjunto de treinamento, até que o Perceptron classifique corretamente todas as amostras (caso elas sejam linearmente separáveis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d3462-f478-4ebd-98bf-8450f3dcd187",
   "metadata": {},
   "source": [
    "================================================================================================================================================  \n",
    "\n",
    "3) *Explique por que o Perceptron somente consegue classificar padrões cuja fronteira de separação entre as classes seja linear*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e6e2b-2ca7-43db-8838-d666ae25a037",
   "metadata": {},
   "source": [
    "*R*: Devido a função de ativição, típico caso de discriminador linear, tendo-se assim como ativação a função sinal:  \n",
    "\\begin{cases}\n",
    "\\text{1}, & \\text{se } x > 0 \\\\\n",
    "\\text{zero}, & \\text{se } x = 0 \\\\\n",
    "\\text{-1}, & \\text{se } x < 0\n",
    "\\end{cases}\n",
    "\n",
    "Em termos matemáticos, a saída do <i>Perceptron</i>, tendo a função sinal (acima) como função ativação:\n",
    "\\begin{cases}\n",
    "1, \\quad \\text{se } \\sum w_i \\cdot x_i - \\theta \\geq 0 \\iff w_1 \\cdot x_1 + w_2 \\cdot x_2 - \\theta \\geq 0 \\\\\n",
    "-1, \\quad \\text{se } \\sum w_i \\cdot x_i - \\theta < 0 \\iff w_1 \\cdot x_1 + w_2 \\cdot x_2 - \\theta < 0\n",
    "\\end{cases}\n",
    "\n",
    "Sendo as desigualdades acima representadas por uma expressão de primeiro grau (linear), a fronteira de decisão para esta instância (<i>Perceptron</i> de duas entradas) será então uma reta cuja equação é definida por:  \n",
    "\\begin{equation}\n",
    "w_1 \\cdot x_1 + x_2 \\cdot w_2 - \\theta = 0\n",
    "\\end{equation}\n",
    "\n",
    "Falei sobre um <i>Perceptron</i> de duas entadas no texto, mas no código utilizamos um <i>Perceptron</i> com 4 entradas, no entando continuou sendo uma forma linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd4101-f146-43bd-8902-3a860f64fd98",
   "metadata": {},
   "source": [
    "================================================================================================================================================  \n",
    "\n",
    "4) *Em termos de implementação computacional descreva a importância de tratarmos o limiar de ativação {$\\theta$} como um dos elementos do vetor de pesos {*W*}.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd69a14-ad5e-4f26-ac53-97bc2f00e8af",
   "metadata": {},
   "source": [
    "*R*: A importância está em tratar as o viés e o peso de forma vetorial, como a mesma regra de ajuste é aplicada tanto para o peso como para o limiar, pode-se inserir o valor do limiar dentro do vetor de pesos.  \n",
    "\\begin{equation}\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "    w_i^{\\text{atual}} = w_i^{\\text{anterior}} + \\eta \\cdot \\left( d^{(k)} - y \\right) \\cdot x_i^{(k)} \\quad & (3.5) \\\\[8pt]\n",
    "    \\theta_i^{\\text{atual}} = \\theta_i^{\\text{anterior}} + \\eta \\cdot \\left( d^{(k)} - y \\right) \\cdot (-1) \\quad & (3.6)\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "\n",
    "Portanto, as expressões (3.5) e (3.6), podem ser representadas por uma única expressão vetorial dada por:  \n",
    "\\begin{equation}\n",
    "\\mathbf{w}^{\\text{atual}} = \\mathbf{w}^{\\text{anterior}} + \\eta \\cdot \\left( d^{(k)} - y \\right) \\cdot \\mathbf{x}^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "Onde:  \n",
    "- $\\mathbf{w}$ é o vetor contendo o limiar (viés) e os pesos  \n",
    "- $\\mathbf{x}^{(k)}$ é a k-ésima amostra do treinamento  \n",
    "- $d^{(k)}$ é o valor desejado para a k-ésima amostra de treinamento  \n",
    "- $y$ é o valor da saída produzida pelo *Perceptron*  \n",
    "- $\\eta$ é uma constante que define a taxa de aprendizagem da rede  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d42aec7-4635-4401-9ae3-a116fcdf5f44",
   "metadata": {},
   "source": [
    "# 3.6 Projeto Prático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdd9ed-c963-4e62-b14a-c3e53589003e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
